<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>PocketSphinx.js</title>
  </head>
  <body>
    <h2>PocketSphinx.js live demo</h2>
    <ul>
      <li>This demo works on recent versions of Chrome and Firefox with the Web Audio API, make sure it works for you and actually records audio.</li>
      <li>Press "Start" and speak</li>
    </ul>
    <select id="grammars"></select>
    <button id="startBtn">Start</button>
    <button id="stopBtn">Stop</button>
    <span id="recording-indicator" style="border-radius: 10px; -moz-border-radius: 10px; -webkit-border-radius: 10px; width: 20px; height: 20px; background: red;"></span>
    <h2>Recognition Output</h2>
    <div id="output" style="height:150px;overflow:auto;" >
    </div>
    <h2>Status</h2>
    <div id="current-status">Loading page</div>

    <script type="module">
      import MicrophoneWorker from './avatars/microphone-worker.js';

      class CallbackManager {
        constructor() {
          this.currentId = 0;
          this.callbackPool = {};
        }
        add(clb) {
          var id = this.currentId;
          this.callbackPool[id] = clb;
          this.currentId++;
          return id;
        }
        get(id) {
          if (this.callbackPool.hasOwnProperty(id)) {
            var clb = this.callbackPool[id];
            delete this.callbackPool[id];
            return clb;
          }
          return null;
        }
      };
      class AudioRecorder {
        constructor(audioContext, consumer) {
          this.audioContext = audioContext;
          this.consumer = consumer;
        }
        start(data) {
          this.consumer.postMessage({ command: 'start', data: data });
        
          const u = '/sounds/pissbaby.mp3';
          const audio = new Audio(u);
          audio.controls = true;
          audio.loop = true;
          audio.addEventListener('canplaythrough', async e => {
            const options = {
              muted: false,
              // emitVolume: true,
              emitBuffer: true,
              audioContext: this.audioContext,
              // microphoneWorkletUrl: 'microphone-worklet.js',
              microphoneWorkletUrl: '/avatars/microphone-worklet.js',
            }
            const microphoneWorker = new MicrophoneWorker(audio, options);
            microphoneWorker.addEventListener('volume', e => {
              console.log('got volume', e);
            });
            const record = (() => {
              const config = {};
              let recBuffers = [];
              var inputBufferLength = config.inputBufferLength || 4096;
              var outputBufferLength = config.outputBufferLength || 4000;
              const inSampleRate = audioContext.sampleRate;
              const outputSampleRate = config.outputSampleRate || 16000;
              
              return inputBuffer => {
                var isSilent = true;
                for (var i = 0 ; i < inputBuffer[0].length ; i++) {
                  recBuffers.push((inputBuffer[0][i] + inputBuffer[1][i]) * 16383.0);
                }
                while (recBuffers.length * outputSampleRate / inSampleRate > outputBufferLength) {
                  var result = new Int16Array(outputBufferLength);
                  var bin = 0,
                  num = 0,
                  indexIn = 0,
                  indexOut = 0;
                  while (indexIn < outputBufferLength) {
                    bin = 0;
                    num = 0;
                    while(indexOut < Math.min(recBuffers.length, (indexIn + 1) * inSampleRate / outputSampleRate)) {
                      bin += recBuffers[indexOut];
                      num += 1;
                      indexOut++;
                    }
                    result[indexIn] = bin / num;
                    if(isSilent && (result[indexIn] != 0)) isSilent = false;
                    indexIn++;
                  }
                  var output = {};
                  output.command = 'newBuffer';
                  output.data = result;
                  if (isSilent) output.error = "silent";
                  
                  this.consumer.postMessage({ command: 'process', data: result });
                  // this.postMessage(output);
                  
                  recBuffers = recBuffers.slice(indexOut);
                }
              };
            })();
            microphoneWorker.addEventListener('buffer', e => {
              const {method, data} = e.data;
              
              const inputBuffer = [
                data,
                data,
              ];
              record(inputBuffer);
            });
            this.microphoneWorker = microphoneWorker;

            await microphoneWorker.waitForLoad();

            audio.play();
            this.audioContext.resume();
          }, {once: true});
          audio.addEventListener('error', e => {
            console.log('load error', e);
          });
        }
        stop() {
          this.consumer.postMessage({ command: 'stop' });
          this.microphoneWorker.close();
        }
        cancel() {
          this.stop();
        }
      }

      let isRecognizerReady = false;

      // These will be initialized later
      var recognizer, recorder, callbackManager, audioContext, outputContainer;
      // Only when both recorder and recognizer do we have a ready application
      var isRecorderReady = isRecognizerReady = false;

      // A convenience function to post a message to the recognizer and associate
      // a callback to its response
      function postRecognizerJob(message, callback) {
        var msg = message || {};
        if (callbackManager) msg.callbackId = callbackManager.add(callback);
        if (recognizer) recognizer.postMessage(msg);
      };

      // This function initializes an instance of the recorder
      // it posts a message right away and calls onReady when it
      // is ready so that onmessage can be properly set
      function spawnWorker(workerURL, onReady) {
          recognizer = new Worker(workerURL);
          recognizer.onmessage = function(event) {
            onReady(recognizer);
          };
          // As arguments, you can pass non-default path to pocketsphinx.js and pocketsphinx.wasm:
          // recognizer.postMessage({'pocketsphinx.wasm': '/path/to/pocketsphinx.wasm', 'pocketsphinx.js': '/path/to/pocketsphinx.js'});
          recognizer.postMessage({
            'pocketsphinx.js': 'pocketsphinx.js',
            'pocketsphinx.wasm': 'pocketsphinx.wasm',
          });
      };

      // To display the hypothesis sent by the recognizer
      function updateHyp(hyp) {
        if (outputContainer) outputContainer.innerHTML = hyp;
      };

      // This updates the UI when the app might get ready
      // Only when both recorder and recognizer are ready do we enable the buttons
      function updateUI() {
        if (isRecorderReady && isRecognizerReady) startBtn.disabled = stopBtn.disabled = false;
      };

      // This is just a logging window where we display the status
      function updateStatus(newStatus) {
        document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
      };

      // A not-so-great recording indicator
      function displayRecording(display) {
        if (display) document.getElementById('recording-indicator').innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;";
        else document.getElementById('recording-indicator').innerHTML = "";
      };

      // Callback function once the user authorises access to the microphone
      // in it, we instanciate the recorder
      function startUserMedia(audioContext) {
        // var input = audioContext.createMediaStreamSource(stream);
        // Firefox hack https://support.mozilla.org/en-US/questions/984179
        // window.firefox_audio_hack = input; 
        // var audioRecorderConfig = {errorCallback: function(x) {updateStatus("Error from recorder: " + x);}};
        recorder = new AudioRecorder(audioContext, recognizer);
        // If a recognizer is ready, we pass it to the recorder
        // recorder.consumers = [recognizer];

        isRecorderReady = true;
        updateUI();
        updateStatus("Audio recorder ready");
      };

      // This starts recording. We first need to get the id of the grammar to use
      var startRecording = function() {
        var id = document.getElementById('grammars').value;
        if (recorder && recorder.start(id)) displayRecording(true);
      };

      // Stops recording
      var stopRecording = function() {
        recorder && recorder.stop();
        displayRecording(false);
      };

      // Called once the recognizer is ready
      // We then add the grammars to the input select tag and update the UI
      var recognizerReady = function() {
           // updateGrammars();
           isRecognizerReady = true;
           updateUI();
           updateStatus("Recognizer ready");
      };

      // This initializes the recognizer. When it calls back, we add words
      var initRecognizer = function() {
          // You can pass parameters to the recognizer, such as : {command: 'initialize', data: [["-hmm", "my_model"], ["-fwdflat", "no"]]}
          postRecognizerJob(
            {
              command: 'initialize',
              data: [/*["-kws", "kws.txt"], ["-dict","kws.dict"], */['-allphone', 'en-us-phone.lm.bin']],
            },
            function() {
              recognizerReady();
            }
          );
      };

      // When the page is loaded, we spawn a new recognizer worker and call getUserMedia to
      // request access to the microphone
      window.onload = function() {
        outputContainer = document.getElementById("output");
        updateStatus("Initializing web audio and speech recognizer, waiting for approval to access the microphone");
        callbackManager = new CallbackManager();
        spawnWorker("/pocketsphinx.js/webapp/js/recognizer.js", function(worker) {
            // This is the onmessage function, once the worker is fully loaded
            worker.onmessage = function(e) {
                // This is the case when we have a callback id to be called
                if (e.data.hasOwnProperty('id')) {
                  var clb = callbackManager.get(e.data['id']);
                  var data = {};
                  if ( e.data.hasOwnProperty('data')) data = e.data.data;
                  if(clb) clb(data);
                }
                // This is a case when the recognizer has a new hypothesis
                if (e.data.hasOwnProperty('hyp')) {
                  var newHyp = e.data.hyp;
                  if (e.data.hasOwnProperty('final') &&  e.data.final) newHyp = "Final: " + newHyp;
                  updateHyp(newHyp);
                }
                // This is the case when we have an error
                if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                  updateStatus("Error in " + e.data.command + " with code " + e.data.code);
                }
            };
            // Once the worker is fully loaded, we can call the initialize function
            // but before that we lazy-load two files for keyword spoting (key phrase
            // file plus associated dictionary.
            
            // console.log('lazy load');
            
            postRecognizerJob({
              command: 'lazyLoad',
              data: {
                // pocketsphinx/model/en-us/en-us-phone.lm.bin
                // folders: [["/", "zh_broadcastnews_ptm256_8000"]],
                folders: [],
                files: [
                  ["/", "en-us-phone.lm.bin", "../../../model/en-us/en-us-phone.lm.bin"],
                  /* ["/zh_broadcastnews_ptm256_8000", "means", "../zh_broadcastnews_ptm256_8000/means"],
                  ["/zh_broadcastnews_ptm256_8000", "variances", "../zh_broadcastnews_ptm256_8000/variances"],
                  ["/zh_broadcastnews_ptm256_8000", "transition_matrices", "../zh_broadcastnews_ptm256_8000/transition_matrices"],
                  ["/zh_broadcastnews_ptm256_8000", "sendump", "../zh_broadcastnews_ptm256_8000/sendump"],
                  ["/zh_broadcastnews_ptm256_8000", "mdef", "../zh_broadcastnews_ptm256_8000/mdef"],
                  ["/zh_broadcastnews_ptm256_8000", "feat.params", "../zh_broadcastnews_ptm256_8000/feat.params"],
                  ["/zh_broadcastnews_ptm256_8000", "mixture_weights", "../zh_broadcastnews_ptm256_8000/mixture_weights"],
                  ["/zh_broadcastnews_ptm256_8000", "noisedict", "../zh_broadcastnews_ptm256_8000/noisedict"] */
                  // ["/", "kws.txt", "../kws.txt"],
                  // ["/", "kws.dict", "../kws.dict"],
                ],
              },
            }, initRecognizer);
        });

        // The following is to initialize Web Audio
        try {
          window.AudioContext = window.AudioContext || window.webkitAudioContext;
          window.URL = window.URL || window.webkitURL;
          audioContext = new AudioContext();
          window.audioContext = audioContext;
        } catch (e) {
          updateStatus("Error initializing Web Audio browser");
        }
        startUserMedia(audioContext);

      // Wiring JavaScript to the UI
      var startBtn = document.getElementById('startBtn');
      var stopBtn = document.getElementById('stopBtn');
      startBtn.disabled = true;
      stopBtn.disabled = true;
      startBtn.onclick = startRecording;
      stopBtn.onclick = stopRecording;
    };
    </script>
  </body>
</html>
