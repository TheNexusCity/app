<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>PocketSphinx.js</title>
  </head>
  <body>
    <h2>PocketSphinx.js live demo</h2>
    <ul>
      <li>This demo works on recent versions of Chrome and Firefox with the Web Audio API, make sure it works for you and actually records audio.</li>
      <li>Press "Start" and speak</li>
    </ul>
    <select id="grammars"></select>
    <button id="startBtn">Start</button>
    <button id="stopBtn">Stop</button>
    <span id="recording-indicator" style="border-radius: 10px; -moz-border-radius: 10px; -webkit-border-radius: 10px; width: 20px; height: 20px; background: red;"></span>
    <h2>Recognition Output</h2>
    <div id="output" style="height:150px;overflow:auto;" >
    </div>
    <h2>Status</h2>
    <div id="current-status">Loading page</div>

    <script type="module">
      import MicrophoneWorker from './avatars/microphone-worker.js';

      const _makePromise = () => {
        let resolve, reject;
        const promise = new Promise((res, rej) => {
          resolve = res;
          reject = rej;
        });
        promise.accept = resolve;
        promise.reject = reject;
        return promise;
      };

      class CallbackManager {
        constructor() {
          this.currentId = 0;
          this.callbackPool = {};
        }
        add(clb) {
          var id = this.currentId;
          this.callbackPool[id] = clb;
          this.currentId++;
          return id;
        }
        get(id) {
          if (this.callbackPool.hasOwnProperty(id)) {
            var clb = this.callbackPool[id];
            delete this.callbackPool[id];
            return clb;
          }
          return null;
        }
      };
      class AudioRecognizer {
        constructor({sampleRate}) {
          this.callbackManager = new CallbackManager();
          this.loadPromise = _makePromise();

          const workerURL = '/pocketsphinx.js/webapp/js/recognizer.js';
          this.worker = new Worker(workerURL);
          this.worker.onmessage = event => {
            this.worker.onmessage = e => {
              // This is the case when we have a callback id to be called
              if (e.data.hasOwnProperty('id')) {
                var clb = this.callbackManager.get(e.data['id']);
                var data = {};
                if ( e.data.hasOwnProperty('data')) data = e.data.data;
                if(clb) clb(data);
              }
              // This is a case when the recognizer has a new hypothesis
              if (e.data.hasOwnProperty('hyp')) {
                var newHyp = e.data.hyp;
                if (e.data.hasOwnProperty('final') &&  e.data.final) newHyp = "Final: " + newHyp;
                updateHyp(newHyp);
              }
              // This is the case when we have an error
              if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                updateStatus("Error in " + e.data.command + " with code " + e.data.code);
              }
            };

            (async () => {
              this.worker.postMessage({ command: 'configure', data: {
                sampleRate,
              } });
              await this.postRecognizerJob({
                command: 'lazyLoad',
                data: {
                  // pocketsphinx/model/en-us/en-us-phone.lm.bin
                  // folders: [["/", "zh_broadcastnews_ptm256_8000"]],
                  folders: [],
                  files: [
                    ["/", "en-us-phone.lm.bin", "../../model/en-us/en-us-phone.lm.bin"],
                    /* ["/zh_broadcastnews_ptm256_8000", "means", "../zh_broadcastnews_ptm256_8000/means"],
                    ["/zh_broadcastnews_ptm256_8000", "variances", "../zh_broadcastnews_ptm256_8000/variances"],
                    ["/zh_broadcastnews_ptm256_8000", "transition_matrices", "../zh_broadcastnews_ptm256_8000/transition_matrices"],
                    ["/zh_broadcastnews_ptm256_8000", "sendump", "../zh_broadcastnews_ptm256_8000/sendump"],
                    ["/zh_broadcastnews_ptm256_8000", "mdef", "../zh_broadcastnews_ptm256_8000/mdef"],
                    ["/zh_broadcastnews_ptm256_8000", "feat.params", "../zh_broadcastnews_ptm256_8000/feat.params"],
                    ["/zh_broadcastnews_ptm256_8000", "mixture_weights", "../zh_broadcastnews_ptm256_8000/mixture_weights"],
                    ["/zh_broadcastnews_ptm256_8000", "noisedict", "../zh_broadcastnews_ptm256_8000/noisedict"] */
                    // ["/", "kws.txt", "../kws.txt"],
                    // ["/", "kws.dict", "../kws.dict"],
                  ],
                },
              });
              await this.postRecognizerJob(
                {
                  command: 'initialize',
                  data: [/*["-kws", "kws.txt"], ["-dict","kws.dict"], */ ['-allphone', 'en-us-phone.lm.bin'], ['-logfn', '/dev/null']],
                }
              );

              this.worker.postMessage({ command: 'start', data: '' });

              this.loadPromise.accept();
            })();
          };

          this.worker.postMessage({
            'pocketsphinx.js': 'pocketsphinx.js',
            'pocketsphinx.wasm': 'pocketsphinx.wasm',
          });
        }
        waitForLoad() {
          return this.loadPromise;
        }
        postRecognizerJob(message) {
          return new Promise((accept, reject) => {
            var msg = message || {};
            msg.callbackId = this.callbackManager.add(accept);
            this.worker.postMessage(msg);
          });
        }
        send(result) {
          this.worker.postMessage({
            command: 'process',
            data: result,
          }, [result.buffer]);
        }
        destroy() {
          this.worker.postMessage({ command: 'stop' });
        }
      }

      let isRecognizerReady = false;

      // These will be initialized later
      let outputContainer;
      // Only when both recorder and recognizer do we have a ready application
      let isRecorderReady = isRecognizerReady = false;

      // To display the hypothesis sent by the recognizer
      function updateHyp(hyp) {
        outputContainer.innerHTML = hyp;
      };

      // This updates the UI when the app might get ready
      // Only when both recorder and recognizer are ready do we enable the buttons
      function updateUI() {
        if (isRecorderReady && isRecognizerReady) startBtn.disabled = stopBtn.disabled = false;
      };

      // This is just a logging window where we display the status
      function updateStatus(newStatus) {
        document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
      };

      // A not-so-great recording indicator
      function displayRecording(display) {
        if (display) document.getElementById('recording-indicator').innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;";
        else document.getElementById('recording-indicator').innerHTML = "";
      };

      // Called once the recognizer is ready
      // We then add the grammars to the input select tag and update the UI
      var recognizerReady = function() {
        // updateGrammars();
        isRecognizerReady = true;
        updateUI();
        updateStatus("Recognizer ready");
      };

      // When the page is loaded, we spawn a new recognizer worker and call getUserMedia to
      // request access to the microphone
      window.onload = async function() {
        outputContainer = document.getElementById("output");
        updateStatus("Initializing web audio and speech recognizer, waiting for approval to access the microphone");

        {
          const audioUrl = '/sounds/pissbaby.mp3';
          // This starts recording. We first need to get the id of the grammar to use
          var startRecording = function() {
            start(audioUrl);
            displayRecording(true);
          };
          // Stops recording
          var stopRecording = function() {
            stop();
            displayRecording(false);
          };

          // Wiring JavaScript to the UI
          var startBtn = document.getElementById('startBtn');
          var stopBtn = document.getElementById('stopBtn');
          startBtn.disabled = true;
          stopBtn.disabled = true;
          startBtn.onclick = startRecording;
          stopBtn.onclick = stopRecording;
        }

        const audioContext = new AudioContext();
        const audioRecognizer = new AudioRecognizer({
          sampleRate: audioContext.sampleRate,
        });
        let microphoneWorker = null;
        function start(audioUrl) {
          const audio = new Audio(audioUrl);
          audio.addEventListener('canplaythrough', async e => {
            const options = {
              muted: false,
              emitBuffer: true,
              audioContext,
              microphoneWorkletUrl: '/avatars/microphone-worklet.js',
            }
            microphoneWorker = new MicrophoneWorker(audio, options);
            microphoneWorker.addEventListener('volume', e => {
              console.log('got volume', e);
            });
            microphoneWorker.addEventListener('buffer', e => {
              audioRecognizer.send(e.data);
            });
          }, {once: true});
          audio.addEventListener('error', e => {
            console.log('load error', e);
          });
          audio.play();
          audioContext.resume();
        }
        function stop() {
          microphoneWorker.close();
        }

        await audioRecognizer.waitForLoad();
        recognizerReady();

        isRecorderReady = true;
        updateUI();
        updateStatus("Audio recorder ready");
      };
    </script>
  </body>
</html>
