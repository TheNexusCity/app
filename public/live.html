<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>PocketSphinx.js</title>
  </head>
  <body>
    <h2>PocketSphinx.js live demo</h2>
    <ul>
      <li>This demo works on recent versions of Chrome and Firefox with the Web Audio API, make sure it works for you and actually records audio.</li>
      <li>Press "Start" and speak</li>
    </ul>
    <select id="grammars"></select>
    <button id="startBtn">Start</button>
    <button id="stopBtn">Stop</button>
    <span id="recording-indicator" style="border-radius: 10px; -moz-border-radius: 10px; -webkit-border-radius: 10px; width: 20px; height: 20px; background: red;"></span>
    <h2>Recognition Output</h2>
    <div id="output" style="height:150px;overflow:auto;" >
    </div>
    <h2>Status</h2>
    <div id="current-status">Loading page</div>

    <script>
      const audioRecorder = () => {
        var AUDIO_RECORDER_WORKER = 'js/audioRecorderWorker.js';
        var AudioRecorder = function(source, cfg) {
        this.consumers = [];
        var config = cfg || {};
        var errorCallback = config.errorCallback || function() {};
        var inputBufferLength = config.inputBufferLength || 4096;
        var outputBufferLength = config.outputBufferLength || 4000;
        this.context = source.context;
        this.node = this.context.createScriptProcessor(inputBufferLength);
        var worker = new Worker(config.worker || AUDIO_RECORDER_WORKER);
        worker.postMessage({
            command: 'init',
            config: {
          sampleRate: this.context.sampleRate,
          outputBufferLength: outputBufferLength,
          outputSampleRate: (config.outputSampleRate || 16000)
            }
        });
        var recording = false;
        this.node.onaudioprocess = function(e) {
          // console.log('audio process');
            if (!recording) return;
            worker.postMessage({
          command: 'record',
          buffer: [
              e.inputBuffer.getChannelData(0),
              e.inputBuffer.getChannelData(1)
          ]
            });
        };
        this.start = function(data) {
          // console.log('start', data, source);
            this.consumers.forEach(function(consumer, y, z) {
                      consumer.postMessage({ command: 'start', data: data });
          recording = true;
          return true;
            });
            recording = true;
            return (this.consumers.length > 0);
        };
        this.stop = function() {
            if (recording) {
          this.consumers.forEach(function(consumer, y, z) {
                          consumer.postMessage({ command: 'stop' });
          });
          recording = false;
            }
            worker.postMessage({ command: 'clear' });
        };
        this.cancel = function() {
            this.stop();
        };
        myClosure = this;
        worker.onmessage = function(e) {
            if (e.data.error && (e.data.error == "silent")) errorCallback("silent");
            if ((e.data.command == 'newBuffer') && recording) {
          myClosure.consumers.forEach(function(consumer, y, z) {
                          consumer.postMessage({ command: 'process', data: e.data.data });
          });
            }
        };
        source.connect(this.node);
        this.node.connect(this.context.destination);
          };
          window.AudioRecorder = AudioRecorder;
      };
      const audioRecorderWorker = () => {
        var recBuffers = [],
          outputSampleRate = 16000,
          inSampleRate;

        this.onmessage = function(e){
          switch(e.data.command){
            case 'init':
              init(e.data.config);
              break;
            case 'record':
              record(e.data.buffer);
              break;
            case 'clear':
              clear();
              break;
          }
        };

        function init(config){
            inSampleRate = config.sampleRate;
            outputBufferLength = config.outputBufferLength;
            outputSampleRate = config.outputSampleRate || outputSampleRate;
        }

        function record(inputBuffer){
            var isSilent = true;
            for (var i = 0 ; i < inputBuffer[0].length ; i++) {
          recBuffers.push((inputBuffer[0][i] + inputBuffer[1][i]) * 16383.0);
            }
            while(recBuffers.length * outputSampleRate / inSampleRate > outputBufferLength) {
          var result = new Int16Array(outputBufferLength);
          var bin = 0,
          num = 0,
          indexIn = 0,
          indexOut = 0;
          while(indexIn < outputBufferLength) {
              bin = 0;
              num = 0;
              while(indexOut < Math.min(recBuffers.length, (indexIn + 1) * inSampleRate / outputSampleRate)) {
            bin += recBuffers[indexOut];
            num += 1;
            indexOut++;
              }
              result[indexIn] = bin / num;
              if(isSilent && (result[indexIn] != 0)) isSilent = false;
              indexIn++;
          }
          var output = {};
          output.command = 'newBuffer';
          output.data = result;
          if (isSilent) output.error = "silent";
          this.postMessage(output);
          recBuffers = recBuffers.slice(indexOut);
            }
        }

        function clear(){
          recBuffers = [];
        }

      };
    </script>






    <script type="module">
      import MicrophoneWorker from './avatars/microphone-worker.js';

      class CallbackManager {
        constructor() {
          this.currentId = 0;
          this.callbackPool = {};
        }
        add(clb) {
          var id = this.currentId;
          this.callbackPool[id] = clb;
          this.currentId++;
          return id;
        }
        get(id) {
          if (this.callbackPool.hasOwnProperty(id)) {
            var clb = this.callbackPool[id];
            delete this.callbackPool[id];
            return clb;
          }
          return null;
        }
      };
      class AudioRecorder {
        constructor(audioContext, consumer) {
          this.audioContext = audioContext;
          this.consumer = consumer;
        }
        start(data) {
          this.consumer.postMessage({ command: 'start', data: data });
        
          const u = '/sounds/pissbaby.mp3';
          const audio = new Audio(u);
          audio.controls = true;
          audio.loop = true;
          audio.addEventListener('canplaythrough', async e => {
            const options = {
              muted: false,
              // emitVolume: true,
              emitBuffer: true,
              audioContext: this.audioContext,
              // microphoneWorkletUrl: 'microphone-worklet.js',
              microphoneWorkletUrl: '/avatars/microphone-worklet.js',
            }
            const microphoneWorker = new MicrophoneWorker(audio, options);
            microphoneWorker.addEventListener('volume', e => {
              console.log('got volume', e);
            });
            const record = (() => {
              const config = {};
              let recBuffers = [];
              var inputBufferLength = config.inputBufferLength || 4096;
              var outputBufferLength = config.outputBufferLength || 4000;
              const inSampleRate = audioContext.sampleRate;
              const outputSampleRate = config.outputSampleRate || 16000;
              
              return inputBuffer => {
                var isSilent = true;
                for (var i = 0 ; i < inputBuffer[0].length ; i++) {
                  recBuffers.push((inputBuffer[0][i] + inputBuffer[1][i]) * 16383.0);
                }
                while (recBuffers.length * outputSampleRate / inSampleRate > outputBufferLength) {
                  var result = new Int16Array(outputBufferLength);
                  var bin = 0,
                  num = 0,
                  indexIn = 0,
                  indexOut = 0;
                  while (indexIn < outputBufferLength) {
                    bin = 0;
                    num = 0;
                    while(indexOut < Math.min(recBuffers.length, (indexIn + 1) * inSampleRate / outputSampleRate)) {
                      bin += recBuffers[indexOut];
                      num += 1;
                      indexOut++;
                    }
                    result[indexIn] = bin / num;
                    if(isSilent && (result[indexIn] != 0)) isSilent = false;
                    indexIn++;
                  }
                  var output = {};
                  output.command = 'newBuffer';
                  output.data = result;
                  if (isSilent) output.error = "silent";
                  
                  this.consumer.postMessage({ command: 'process', data: result });
                  // this.postMessage(output);
                  
                  recBuffers = recBuffers.slice(indexOut);
                }
              };
            })();
            microphoneWorker.addEventListener('buffer', e => {
              const {method, data} = e.data;
              
              // console.log('got buffer', method, data);
              const inputBuffer = [
                data,
                data,
              ];
              record(inputBuffer);
              
              // console.log('got buffer', e, buffer);
              /* this.consumer.postMessage({
                command: 'record',
                buffer: [
                  // e.inputBuffer.getChannelData(0),
                  // e.inputBuffer.getChannelData(1),
                  buffer,
                  buffer,
                ]
              }); */
            });

            await microphoneWorker.waitForLoad();

            audio.play();
            this.audioContext.resume();

            /* const response = await fetch(u)
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await context.decodeAudioData(arrayBuffer);
            console.log('got audio buffer', audioBuffer); */
          }, {once: true});
          audio.addEventListener('error', e => {
            console.log('load error', e);
          });
          window.audio = audio;
          // console.log('create audio', audio);
          document.body.appendChild(audio);
        }
        stop() {
          this.consumer.postMessage({ command: 'stop' });
        }
        cancel() {
          this.stop();
        }
        extra() {
          var AUDIO_RECORDER_WORKER = 'js/audioRecorderWorker.js';
          var AudioRecorder = function(source, cfg) {
          this.consumers = [];
          var config = cfg || {};
          var errorCallback = config.errorCallback || function() {};
          var inputBufferLength = config.inputBufferLength || 4096;
          var outputBufferLength = config.outputBufferLength || 4000;
          this.context = source.context;
          this.node = this.context.createScriptProcessor(inputBufferLength);
          var worker = new Worker(config.worker || AUDIO_RECORDER_WORKER);
          worker.postMessage({
              command: 'init',
              config: {
            sampleRate: this.context.sampleRate,
            outputBufferLength: outputBufferLength,
            outputSampleRate: (config.outputSampleRate || 16000)
              }
          });
          var recording = false;
          this.node.onaudioprocess = function(e) {
            // console.log('audio process');
              if (!recording) return;
              worker.postMessage({
            command: 'record',
            buffer: [
                e.inputBuffer.getChannelData(0),
                e.inputBuffer.getChannelData(1)
            ]
              });
          };
          this.start = function(data) {
            // console.log('start', data, source);
              this.consumers.forEach(function(consumer, y, z) {
                        consumer.postMessage({ command: 'start', data: data });
            recording = true;
            return true;
              });
              recording = true;
              return (this.consumers.length > 0);
          };
          this.stop = function() {
              if (recording) {
            this.consumers.forEach(function(consumer, y, z) {
                            consumer.postMessage({ command: 'stop' });
            });
            recording = false;
              }
              worker.postMessage({ command: 'clear' });
          };
          this.cancel = function() {
              this.stop();
          };
          myClosure = this;
          worker.onmessage = function(e) {
              if (e.data.error && (e.data.error == "silent")) errorCallback("silent");
              if ((e.data.command == 'newBuffer') && recording) {
            myClosure.consumers.forEach(function(consumer, y, z) {
                            consumer.postMessage({ command: 'process', data: e.data.data });
            });
              }
          };
          source.connect(this.node);
          this.node.connect(this.context.destination);
            };
            window.AudioRecorder = AudioRecorder;
        }
      }



      

      let isRecognizerReady = false;

      // These will be initialized later
      var recognizer, recorder, callbackManager, audioContext, outputContainer;
      // Only when both recorder and recognizer do we have a ready application
      var isRecorderReady = isRecognizerReady = false;

      // A convenience function to post a message to the recognizer and associate
      // a callback to its response
      function postRecognizerJob(message, callback) {
        var msg = message || {};
        if (callbackManager) msg.callbackId = callbackManager.add(callback);
        if (recognizer) recognizer.postMessage(msg);
      };

      // This function initializes an instance of the recorder
      // it posts a message right away and calls onReady when it
      // is ready so that onmessage can be properly set
      function spawnWorker(workerURL, onReady) {
          recognizer = new Worker(workerURL);
          recognizer.onmessage = function(event) {
            onReady(recognizer);
          };
          // As arguments, you can pass non-default path to pocketsphinx.js and pocketsphinx.wasm:
          // recognizer.postMessage({'pocketsphinx.wasm': '/path/to/pocketsphinx.wasm', 'pocketsphinx.js': '/path/to/pocketsphinx.js'});
          recognizer.postMessage({
            'pocketsphinx.js': 'pocketsphinx.js',
            'pocketsphinx.wasm': 'pocketsphinx.wasm',
          });
      };

      // To display the hypothesis sent by the recognizer
      function updateHyp(hyp) {
        if (outputContainer) outputContainer.innerHTML = hyp;
      };

      // This updates the UI when the app might get ready
      // Only when both recorder and recognizer are ready do we enable the buttons
      function updateUI() {
        if (isRecorderReady && isRecognizerReady) startBtn.disabled = stopBtn.disabled = false;
      };

      // This is just a logging window where we display the status
      function updateStatus(newStatus) {
        document.getElementById('current-status').innerHTML += "<br/>" + newStatus;
      };

      // A not-so-great recording indicator
      function displayRecording(display) {
        if (display) document.getElementById('recording-indicator').innerHTML = "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;";
        else document.getElementById('recording-indicator').innerHTML = "";
      };

      // Callback function once the user authorises access to the microphone
      // in it, we instanciate the recorder
      function startUserMedia(audioContext) {
        // var input = audioContext.createMediaStreamSource(stream);
        // Firefox hack https://support.mozilla.org/en-US/questions/984179
        // window.firefox_audio_hack = input; 
        // var audioRecorderConfig = {errorCallback: function(x) {updateStatus("Error from recorder: " + x);}};
        recorder = new AudioRecorder(audioContext, recognizer);
        // If a recognizer is ready, we pass it to the recorder
        // recorder.consumers = [recognizer];

        isRecorderReady = true;
        updateUI();
        updateStatus("Audio recorder ready");
      };

      // This starts recording. We first need to get the id of the grammar to use
      var startRecording = function() {
        var id = document.getElementById('grammars').value;
        if (recorder && recorder.start(id)) displayRecording(true);
      };

      // Stops recording
      var stopRecording = function() {
        recorder && recorder.stop();
        displayRecording(false);
      };

      // Called once the recognizer is ready
      // We then add the grammars to the input select tag and update the UI
      var recognizerReady = function() {
           updateGrammars();
           isRecognizerReady = true;
           updateUI();
           updateStatus("Recognizer ready");
      };

      // We get the grammars defined below and fill in the input select tag
      var updateGrammars = function() {
        var selectTag = document.getElementById('grammars');
        for (var i = 0 ; i < grammarIds.length ; i++) {
            var newElt = document.createElement('option');
            newElt.value=grammarIds[i].id;
            newElt.innerHTML = grammarIds[i].title;
            selectTag.appendChild(newElt);
        }                          
      };

      // This adds a grammar from the grammars array
      // We add them one by one and call it again as
      // a callback.
      // Once we are done adding all grammars, we can call
      // recognizerReady()
      var feedGrammar = function(g, index, id) {
        if (id && (grammarIds.length > 0)) grammarIds[0].id = id.id;
        if (index < g.length) {
          grammarIds.unshift({title: g[index].title});
          postRecognizerJob({command: 'addGrammar', data: g[index].g},
                              function(id) {feedGrammar(grammars, index + 1, {id:id});});
        } else {
          // We are adding keyword spotting which has id 0
          grammarIds.push({"id":0, "title": "Keyword spotting"});
          recognizerReady();
        }
      };

      // This adds words to the recognizer. When it calls back, we add grammars
      var feedWords = function(words) {
        postRecognizerJob(
          {
            command: 'addWords',
            data: words,
          },
          function() {
            // feedGrammar(grammars, 0);
            recognizerReady();
          }
        );
      };

      // This initializes the recognizer. When it calls back, we add words
      var initRecognizer = function() {
          // You can pass parameters to the recognizer, such as : {command: 'initialize', data: [["-hmm", "my_model"], ["-fwdflat", "no"]]}
          postRecognizerJob(
            {
              command: 'initialize',
              data: [["-kws", "kws.txt"], ["-dict","kws.dict"], ['-allphone', 'en-us-phone.lm.bin']],
            },
            function() {
              if (recorder) recorder.consumers = [recognizer];
              feedWords(wordList);
            }
          );
      };

      // When the page is loaded, we spawn a new recognizer worker and call getUserMedia to
      // request access to the microphone
      window.onload = function() {
        outputContainer = document.getElementById("output");
        updateStatus("Initializing web audio and speech recognizer, waiting for approval to access the microphone");
        callbackManager = new CallbackManager();
        spawnWorker("/pocketsphinx.js/webapp/js/recognizer.js", function(worker) {
            // This is the onmessage function, once the worker is fully loaded
            worker.onmessage = function(e) {
                // This is the case when we have a callback id to be called
                if (e.data.hasOwnProperty('id')) {
                  var clb = callbackManager.get(e.data['id']);
                  var data = {};
                  if ( e.data.hasOwnProperty('data')) data = e.data.data;
                  if(clb) clb(data);
                }
                // This is a case when the recognizer has a new hypothesis
                if (e.data.hasOwnProperty('hyp')) {
                  var newHyp = e.data.hyp;
                  if (e.data.hasOwnProperty('final') &&  e.data.final) newHyp = "Final: " + newHyp;
                  updateHyp(newHyp);
                }
                // This is the case when we have an error
                if (e.data.hasOwnProperty('status') && (e.data.status == "error")) {
                  updateStatus("Error in " + e.data.command + " with code " + e.data.code);
                }
            };
            // Once the worker is fully loaded, we can call the initialize function
            // but before that we lazy-load two files for keyword spoting (key phrase
            // file plus associated dictionary.
            
            // console.log('lazy load');
            
            postRecognizerJob({
              command: 'lazyLoad',
              data: {
                // pocketsphinx/model/en-us/en-us-phone.lm.bin
                // folders: [["/", "zh_broadcastnews_ptm256_8000"]],
                folders: [],
                files: [
                  ["/", "en-us-phone.lm.bin", "../../../model/en-us/en-us-phone.lm.bin"],
                  /* ["/zh_broadcastnews_ptm256_8000", "means", "../zh_broadcastnews_ptm256_8000/means"],
                  ["/zh_broadcastnews_ptm256_8000", "variances", "../zh_broadcastnews_ptm256_8000/variances"],
                  ["/zh_broadcastnews_ptm256_8000", "transition_matrices", "../zh_broadcastnews_ptm256_8000/transition_matrices"],
                  ["/zh_broadcastnews_ptm256_8000", "sendump", "../zh_broadcastnews_ptm256_8000/sendump"],
                  ["/zh_broadcastnews_ptm256_8000", "mdef", "../zh_broadcastnews_ptm256_8000/mdef"],
                  ["/zh_broadcastnews_ptm256_8000", "feat.params", "../zh_broadcastnews_ptm256_8000/feat.params"],
                  ["/zh_broadcastnews_ptm256_8000", "mixture_weights", "../zh_broadcastnews_ptm256_8000/mixture_weights"],
                  ["/zh_broadcastnews_ptm256_8000", "noisedict", "../zh_broadcastnews_ptm256_8000/noisedict"] */
                  ["/", "kws.txt", "../kws.txt"],
                  ["/", "kws.dict", "../kws.dict"],
                ],
              },
            }, initRecognizer);
        });

        // The following is to initialize Web Audio
        try {
          window.AudioContext = window.AudioContext || window.webkitAudioContext;
          window.URL = window.URL || window.webkitURL;
          audioContext = new AudioContext();
          window.audioContext = audioContext;
        } catch (e) {
          updateStatus("Error initializing Web Audio browser");
        }
        startUserMedia(audioContext);

      // Wiring JavaScript to the UI
      var startBtn = document.getElementById('startBtn');
      var stopBtn = document.getElementById('stopBtn');
      startBtn.disabled = true;
      stopBtn.disabled = true;
      startBtn.onclick = startRecording;
      stopBtn.onclick = stopRecording;
      };

       // This is the list of words that need to be added to the recognizer
       // This follows the CMU dictionary format
      var wordList = [["ONE", "W AH N"], ["TWO", "T UW"], ["THREE", "TH R IY"], ["FOUR", "F AO R"], ["FIVE", "F AY V"], ["SIX", "S IH K S"], ["SEVEN", "S EH V AH N"], ["EIGHT", "EY T"], ["NINE", "N AY N"], ["ZERO", "Z IH R OW"], ["NEW-YORK", "N UW Y AO R K"], ["NEW-YORK-CITY", "N UW Y AO R K S IH T IY"], ["PARIS", "P AE R IH S"] , ["PARIS(2)", "P EH R IH S"], ["SHANGHAI", "SH AE NG HH AY"], ["SAN-FRANCISCO", "S AE N F R AE N S IH S K OW"], ["LONDON", "L AH N D AH N"], ["BERLIN", "B ER L IH N"], ["SUCKS", "S AH K S"], ["ROCKS", "R AA K S"], ["IS", "IH Z"], ["NOT", "N AA T"], ["GOOD", "G IH D"], ["GOOD(2)", "G UH D"], ["GREAT", "G R EY T"], ["WINDOWS", "W IH N D OW Z"], ["LINUX", "L IH N AH K S"], ["UNIX", "Y UW N IH K S"], ["MAC", "M AE K"], ["AND", "AE N D"], ["AND(2)", "AH N D"], ["O", "OW"], ["S", "EH S"], ["X", "EH K S"]];
      // This grammar recognizes digits
      var grammarDigits = {numStates: 1, start: 0, end: 0, transitions: [{from: 0, to: 0, word: "ONE"},{from: 0, to: 0, word: "TWO"},{from: 0, to: 0, word: "THREE"},{from: 0, to: 0, word: "FOUR"},{from: 0, to: 0, word: "FIVE"},{from: 0, to: 0, word: "SIX"},{from: 0, to: 0, word: "SEVEN"},{from: 0, to: 0, word: "EIGHT"},{from: 0, to: 0, word: "NINE"},{from: 0, to: 0, word: "ZERO"}]};
      // This grammar recognizes a few cities names
      var grammarCities = {numStates: 1, start: 0, end: 0, transitions: [{from: 0, to: 0, word: "NEW-YORK"}, {from: 0, to: 0, word: "NEW-YORK-CITY"}, {from: 0, to: 0, word: "PARIS"}, {from: 0, to: 0, word: "SHANGHAI"}, {from: 0, to: 0, word: "SAN-FRANCISCO"}, {from: 0, to: 0, word: "LONDON"}, {from: 0, to: 0, word: "BERLIN"}]};
      // This is to play with beloved or belated OSes
      var grammarOses = {numStates: 7, start: 0, end: 6, transitions: [{from: 0, to: 1, word: "WINDOWS"}, {from: 0, to: 1, word: "LINUX"}, {from: 0, to: 1, word: "UNIX"}, {from: 1, to: 2, word: "IS"}, {from: 2, to: 2, word: "NOT"}, {from: 2, to: 6, word: "GOOD"}, {from: 2, to: 6, word: "GREAT"}, {from: 1, to: 6, word: "ROCKS"}, {from: 1, to: 6, word: "SUCKS"}, {from: 0, to: 4, word: "MAC"}, {from: 4, to: 5, word: "O"}, {from: 5, to: 3, word: "S"}, {from: 3, to: 1, word: "X"}, {from: 6, to: 0, word: "AND"}]};
      var grammars = [{title: "OSes", g: grammarOses}, {title: "Digits", g: grammarDigits}, {title: "Cities", g: grammarCities}];
      var grammarIds = [];
    </script>
    <!-- These are the two JavaScript files you must load in the HTML,
    The recognizer is loaded through a Web Worker -->
    <!-- <script src="js/audioRecorder.js"></script> -->
    <!-- <script src="js/callbackManager.js"></script> -->
  </body>
</html>
